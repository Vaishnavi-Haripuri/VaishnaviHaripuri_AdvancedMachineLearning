{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment on Text and Sequence\n",
        "\n",
        "-By Vaishnavi Haripuri\n",
        "811285838"
      ],
      "metadata": {
        "id": "yud0_E3qnIkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modifying Parameters and Data Preprocessing\n",
        "\n",
        "1. Cutoff reviews after 150 words.\n",
        "2. Restrict training samples to 100.\n",
        "3. Validate on 10,000 samples.\n",
        "4. Consider only the top 10,000 words."
      ],
      "metadata": {
        "id": "90SGevMCj5jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the IMDB dataset\n",
        "max_features = 10000  # Consider only the top 10,000 words\n",
        "maxlen = 150          # Cutoff after 150 words\n",
        "training_samples = 100  # Restrict training samples to 100\n",
        "validation_samples = 10000  # Validate on 10,000 samples\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Limit training data to 100 samples\n",
        "x_train = x_train[:training_samples]\n",
        "y_train = y_train[:training_samples]\n",
        "\n",
        "# Pad the sequences to ensure all reviews have the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Reserve 10,000 samples for validation\n",
        "x_val = x_test[:validation_samples]\n",
        "y_val = y_test[:validation_samples]\n"
      ],
      "metadata": {
        "id": "8pO7bFA-zxUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Model Architecture with Embedding Layer"
      ],
      "metadata": {
        "id": "wajJ0ziCkKzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with trainable embedding layer\n",
        "model_embedding = Sequential([\n",
        "    Embedding(max_features, 50, input_length=maxlen),  # Embedding layer\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_embedding.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fTuER0C8z4zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history_embedding = model_embedding.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=15,\n",
        "    batch_size=32,\n",
        "    validation_data=(x_val, y_val),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "tiaXJ1c14dxP",
        "outputId": "84633516-580d-45ac-beb6-932982830fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.5262 - val_loss: 0.7827\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.5256 - val_loss: 0.7875\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.5250 - val_loss: 0.7901\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.5248 - val_loss: 0.7927\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.5252 - val_loss: 0.7958\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.5254 - val_loss: 0.8000\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5251 - val_loss: 0.8049\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.5256 - val_loss: 0.8097\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.5261 - val_loss: 0.8126\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.5264 - val_loss: 0.8147\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.5260 - val_loss: 0.8168\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 451ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5260 - val_loss: 0.8188\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 457ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5263 - val_loss: 0.8204\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.5265 - val_loss: 0.8220\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5269 - val_loss: 0.8236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# Adjust word indices by shifting the indices by 3 (to account for padding, start, and unknown tokens)\n",
        "word_index = {word: index + 3 for word, index in word_index.items()}\n",
        "\n",
        "embedding_matrix = np.zeros((max_features, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i < max_features:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n"
      ],
      "metadata": {
        "id": "UP6HoCCy8r9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Embedding(max_features, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=True)\n"
      ],
      "metadata": {
        "id": "Jo8d9_Rz8tGw",
        "outputId": "5810f32c-a005-4f4e-d20a-e9dbb52500e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Embedding name=embedding_9, built=True>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining Model with Pretrained Word Embeddings ( GloVe)"
      ],
      "metadata": {
        "id": "g_xtbIkDkbQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pretrained = Sequential([\n",
        "    Embedding(max_features, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=True),\n",
        "    Flatten(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)  # Try a lower learning rate\n",
        "model_pretrained.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "UvFG2bFO9QHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_pretrained = model_pretrained.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=15,\n",
        "    batch_size=32,\n",
        "    validation_data=(x_val, y_val),\n",
        ")\n"
      ],
      "metadata": {
        "id": "TyFOI7609hO6",
        "outputId": "08188089-14e0-4d15-8308-a96582672d66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 0.7458 - loss: 0.5829 - val_accuracy: 0.5133 - val_loss: 0.7148\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 0.8090 - loss: 0.5444 - val_accuracy: 0.5157 - val_loss: 0.7130\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 199ms/step - accuracy: 0.8139 - loss: 0.5098 - val_accuracy: 0.5193 - val_loss: 0.7090\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.8209 - loss: 0.4934 - val_accuracy: 0.5206 - val_loss: 0.7094\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.8511 - loss: 0.4751 - val_accuracy: 0.5224 - val_loss: 0.7128\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 0.8299 - loss: 0.4709 - val_accuracy: 0.5244 - val_loss: 0.7171\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.8382 - loss: 0.4369 - val_accuracy: 0.5232 - val_loss: 0.7217\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 0.9182 - loss: 0.3846 - val_accuracy: 0.5242 - val_loss: 0.7243\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - accuracy: 0.8681 - loss: 0.3849 - val_accuracy: 0.5265 - val_loss: 0.7298\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.8760 - loss: 0.3739 - val_accuracy: 0.5286 - val_loss: 0.7296\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step - accuracy: 0.9110 - loss: 0.3223 - val_accuracy: 0.5305 - val_loss: 0.7294\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 353ms/step - accuracy: 0.9621 - loss: 0.2859 - val_accuracy: 0.5318 - val_loss: 0.7260\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 450ms/step - accuracy: 0.9600 - loss: 0.2949 - val_accuracy: 0.5335 - val_loss: 0.7271\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 348ms/step - accuracy: 0.9383 - loss: 0.2995 - val_accuracy: 0.5350 - val_loss: 0.7296\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 0.9838 - loss: 0.2797 - val_accuracy: 0.5370 - val_loss: 0.7345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#changing the number of training samples"
      ],
      "metadata": {
        "id": "C_OdqUtiknBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experimenting with different training sample sizes\n",
        "training_sample_sizes = [100, 500, 1000, 2000]\n",
        "\n",
        "results = {}\n",
        "for sample_size in training_sample_sizes:\n",
        "    # Limit training data to sample_size\n",
        "    x_train = x_train[:sample_size]\n",
        "    y_train = y_train[:sample_size]\n",
        "\n",
        "    # Train both models with the new sample size\n",
        "    history_embedding = model_embedding.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=15,\n",
        "        batch_size=32,\n",
        "        validation_data=(x_val, y_val),\n",
        "    )\n",
        "\n",
        "    history_pretrained = model_pretrained.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=15,\n",
        "        batch_size=32,\n",
        "        validation_data=(x_val, y_val),\n",
        "        )\n",
        "\n",
        "    # Record the performance of both models for comparison\n",
        "    results[sample_size] = {\n",
        "        'embedding_acc': history_embedding.history['val_accuracy'][-1],\n",
        "        'pretrained_acc': history_pretrained.history['val_accuracy'][-1]\n",
        "    }\n",
        "\n",
        "# Print results to compare the performance\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "2TjZBFn7_I4f",
        "outputId": "dac5473b-aea6-483c-9688-52a0a7bfbdb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391ms/step - accuracy: 1.0000 - loss: 4.4569e-04 - val_accuracy: 0.5278 - val_loss: 0.9449\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 3.6424e-04 - val_accuracy: 0.5272 - val_loss: 0.9484\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - accuracy: 1.0000 - loss: 4.6609e-04 - val_accuracy: 0.5275 - val_loss: 0.9518\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 4.7175e-04 - val_accuracy: 0.5277 - val_loss: 0.9537\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5269 - val_loss: 0.9560\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 4.7259e-04 - val_accuracy: 0.5277 - val_loss: 0.9578\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.5273 - val_loss: 0.9587\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5278 - val_loss: 0.9578\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 9.2338e-04 - val_accuracy: 0.5270 - val_loss: 0.9585\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 8.5056e-04 - val_accuracy: 0.5274 - val_loss: 0.9599\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5271 - val_loss: 0.9617\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 4.9897e-04 - val_accuracy: 0.5276 - val_loss: 0.9635\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5274 - val_loss: 0.9653\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 8.2318e-04 - val_accuracy: 0.5276 - val_loss: 0.9675\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5266 - val_loss: 0.9711\n",
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0410 - val_accuracy: 0.5400 - val_loss: 0.8443\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0365 - val_accuracy: 0.5411 - val_loss: 0.8506\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 0.0516 - val_accuracy: 0.5414 - val_loss: 0.8558\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 1.0000 - loss: 0.0252 - val_accuracy: 0.5418 - val_loss: 0.8629\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 346ms/step - accuracy: 1.0000 - loss: 0.0250 - val_accuracy: 0.5406 - val_loss: 0.8627\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.5417 - val_loss: 0.8634\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.5417 - val_loss: 0.8603\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 194ms/step - accuracy: 1.0000 - loss: 0.0451 - val_accuracy: 0.5411 - val_loss: 0.8599\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.5412 - val_loss: 0.8541\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 0.0316 - val_accuracy: 0.5409 - val_loss: 0.8466\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0249 - val_accuracy: 0.5413 - val_loss: 0.8413\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0390 - val_accuracy: 0.5404 - val_loss: 0.8484\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 0.5409 - val_loss: 0.8566\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0277 - val_accuracy: 0.5415 - val_loss: 0.8611\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.5430 - val_loss: 0.8672\n",
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 7.8175e-04 - val_accuracy: 0.5262 - val_loss: 0.9752\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 2.4519e-04 - val_accuracy: 0.5254 - val_loss: 0.9781\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 6.0814e-04 - val_accuracy: 0.5241 - val_loss: 0.9810\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 2.3465e-04 - val_accuracy: 0.5238 - val_loss: 0.9834\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 448ms/step - accuracy: 1.0000 - loss: 5.7429e-04 - val_accuracy: 0.5237 - val_loss: 0.9858\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5238 - val_loss: 0.9865\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 9.2423e-04 - val_accuracy: 0.5240 - val_loss: 0.9892\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 8.1533e-04 - val_accuracy: 0.5235 - val_loss: 0.9983\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5229 - val_loss: 1.0074\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 2.5950e-04 - val_accuracy: 0.5223 - val_loss: 1.0150\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 5.2429e-04 - val_accuracy: 0.5210 - val_loss: 1.0204\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5217 - val_loss: 1.0256\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 3.3761e-04 - val_accuracy: 0.5218 - val_loss: 1.0292\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 6.5902e-04 - val_accuracy: 0.5218 - val_loss: 1.0296\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5214 - val_loss: 1.0318\n",
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0274 - val_accuracy: 0.5432 - val_loss: 0.8722\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0319 - val_accuracy: 0.5435 - val_loss: 0.8757\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 0.5428 - val_loss: 0.8753\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0370 - val_accuracy: 0.5417 - val_loss: 0.8654\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0176 - val_accuracy: 0.5409 - val_loss: 0.8638\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.5417 - val_loss: 0.8698\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.5414 - val_loss: 0.8749\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 315ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.5416 - val_loss: 0.8725\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.5422 - val_loss: 0.8708\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - accuracy: 1.0000 - loss: 0.0307 - val_accuracy: 0.5432 - val_loss: 0.8679\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0195 - val_accuracy: 0.5421 - val_loss: 0.8764\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.0244 - val_accuracy: 0.5421 - val_loss: 0.8787\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.5440 - val_loss: 0.8635\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0276 - val_accuracy: 0.5444 - val_loss: 0.8607\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 0.5437 - val_loss: 0.8673\n",
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 3.0641e-04 - val_accuracy: 0.5218 - val_loss: 1.0354\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 9.7511e-04 - val_accuracy: 0.5217 - val_loss: 1.0392\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 3.4098e-04 - val_accuracy: 0.5217 - val_loss: 1.0413\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5216 - val_loss: 1.0428\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 2.8022e-04 - val_accuracy: 0.5217 - val_loss: 1.0445\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 7.6693e-04 - val_accuracy: 0.5213 - val_loss: 1.0456\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 2.6613e-04 - val_accuracy: 0.5214 - val_loss: 1.0464\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445ms/step - accuracy: 1.0000 - loss: 1.1073e-04 - val_accuracy: 0.5213 - val_loss: 1.0464\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 1.0000 - loss: 1.7577e-04 - val_accuracy: 0.5210 - val_loss: 1.0455\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 1.0000 - loss: 1.5607e-04 - val_accuracy: 0.5214 - val_loss: 1.0447\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 2.9890e-04 - val_accuracy: 0.5213 - val_loss: 1.0429\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 2.0379e-04 - val_accuracy: 0.5210 - val_loss: 1.0405\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 1.5579e-04 - val_accuracy: 0.5222 - val_loss: 1.0362\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5224 - val_loss: 1.0361\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 3.2178e-04 - val_accuracy: 0.5223 - val_loss: 1.0424\n",
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.0284 - val_accuracy: 0.5450 - val_loss: 0.8797\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 0.0235 - val_accuracy: 0.5433 - val_loss: 0.8949\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0210 - val_accuracy: 0.5428 - val_loss: 0.9042\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.5433 - val_loss: 0.9071\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.5430 - val_loss: 0.9042\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.5448 - val_loss: 0.8989\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0343 - val_accuracy: 0.5443 - val_loss: 0.8951\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0219 - val_accuracy: 0.5451 - val_loss: 0.8989\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.5445 - val_loss: 0.9057\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0259 - val_accuracy: 0.5435 - val_loss: 0.9122\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0199 - val_accuracy: 0.5435 - val_loss: 0.9194\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.5431 - val_loss: 0.9226\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.5450 - val_loss: 0.9309\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.5433 - val_loss: 0.9372\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.5439 - val_loss: 0.9342\n",
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 3.3478e-04 - val_accuracy: 0.5218 - val_loss: 1.0469\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 341ms/step - accuracy: 1.0000 - loss: 5.4645e-04 - val_accuracy: 0.5219 - val_loss: 1.0491\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - accuracy: 1.0000 - loss: 6.5150e-04 - val_accuracy: 0.5223 - val_loss: 1.0518\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 451ms/step - accuracy: 1.0000 - loss: 6.4975e-04 - val_accuracy: 0.5219 - val_loss: 1.0537\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.7127e-04 - val_accuracy: 0.5220 - val_loss: 1.0550\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 4.5920e-04 - val_accuracy: 0.5218 - val_loss: 1.0565\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.5222 - val_loss: 1.0594\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 5.7709e-05 - val_accuracy: 0.5226 - val_loss: 1.0617\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.5222 - val_loss: 1.0684\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 2.8469e-04 - val_accuracy: 0.5217 - val_loss: 1.0772\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 5.1528e-04 - val_accuracy: 0.5207 - val_loss: 1.0830\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 8.8230e-04 - val_accuracy: 0.5205 - val_loss: 1.0863\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 4.0427e-04 - val_accuracy: 0.5205 - val_loss: 1.0888\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186ms/step - accuracy: 1.0000 - loss: 1.0495e-04 - val_accuracy: 0.5206 - val_loss: 1.0905\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 4.7828e-04 - val_accuracy: 0.5210 - val_loss: 1.0922\n",
            "Epoch 1/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.5427 - val_loss: 0.9268\n",
            "Epoch 2/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 447ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.5433 - val_loss: 0.9223\n",
            "Epoch 3/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.5438 - val_loss: 0.9105\n",
            "Epoch 4/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 448ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.5445 - val_loss: 0.9066\n",
            "Epoch 5/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 459ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.5434 - val_loss: 0.9120\n",
            "Epoch 6/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.5429 - val_loss: 0.9307\n",
            "Epoch 7/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.5442 - val_loss: 0.9426\n",
            "Epoch 8/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.5436 - val_loss: 0.9481\n",
            "Epoch 9/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.5433 - val_loss: 0.9564\n",
            "Epoch 10/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.5433 - val_loss: 0.9631\n",
            "Epoch 11/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.5435 - val_loss: 0.9648\n",
            "Epoch 12/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.5439 - val_loss: 0.9557\n",
            "Epoch 13/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0178 - val_accuracy: 0.5422 - val_loss: 0.9399\n",
            "Epoch 14/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.5446 - val_loss: 0.9281\n",
            "Epoch 15/15\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.5451 - val_loss: 0.9185\n",
            "{100: {'embedding_acc': 0.5266000032424927, 'pretrained_acc': 0.5429999828338623}, 500: {'embedding_acc': 0.521399974822998, 'pretrained_acc': 0.5436999797821045}, 1000: {'embedding_acc': 0.5223000049591064, 'pretrained_acc': 0.5439000129699707}, 2000: {'embedding_acc': 0.5210000276565552, 'pretrained_acc': 0.5450999736785889}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Observed Performance of embedding layer :\n",
        "\n",
        "Epoch 13–15 in the last model training session:\n",
        "\n",
        "Validation accuracy was ~54.4% (highest among the epochs observed).\n",
        "Validation loss reached a minimum of 0.8607, suggesting the embedding layer performed best at this point."
      ],
      "metadata": {
        "id": "dDSBQ2QmmYmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparing Performance"
      ],
      "metadata": {
        "id": "iu7kgyghkxFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For 100 samples:\n",
        "Embedding model accuracy: 0.5258\n",
        "Pretrained model accuracy: 0.5346\n",
        "#For 500 samples:\n",
        "Embedding model accuracy: 0.5269\n",
        "Pretrained model accuracy: 0.5376\n",
        "#For 1000 samples:\n",
        "Embedding model accuracy: 0.5270\n",
        "Pretrained model accuracy: 0.5405\n",
        "#For 2000 samples:\n",
        "Embedding model accuracy: 0.5277\n",
        "Pretrained model accuracy: 0.5405\n",
        "\n",
        "#Conclusion:\n",
        "\n",
        "At every training sample size, the pretrained embedding model performs marginally better than the embedding model. The pretrained model appears to perform slightly better, despite the tiny variations, indicating that even with fewer training datasets, employing pretrained embeddings is advantageous."
      ],
      "metadata": {
        "id": "klslJP-cBExA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance trend based on different training size for pretrained model\n",
        "\n",
        "100 samples: Pretrained model accuracy = 0.5346\n",
        "\n",
        "500 samples: Pretrained model accuracy = 0.5376\n",
        "\n",
        "1000 samples: Pretrained model accuracy = 0.5405\n",
        "\n",
        "2000 samples: Pretrained model accuracy = 0.5405\n",
        "\n",
        "\n",
        "The pretrained model’s accuracy increases slightly as you go from 100 to 1000 samples but then stabilizes at 2000 samples (no further increase in accuracy from 1000 to 2000).\n",
        "For the pretrained model, you get a stable accuracy of 0.5405 starting from 1000 samples, and there's no noticeable improvement with more samples (2000).\n",
        "\n",
        "\n",
        "Best choice: 1000 samples seems to be a good compromise. The accuracy is relatively high, and adding more samples (up to 2000) doesn't provide significant improvement."
      ],
      "metadata": {
        "id": "N4pZooNuBMH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sl42Ee0_l2Cv"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}